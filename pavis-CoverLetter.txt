  > In particular, they found that the topics of fused visualization
  > and uncertainty lacked depth and clarity in the paper, despite the
  > prominent role that these aspects were supposed to play.
The last paragraph of the introduction was rewritten to make the distinction
between the two different kinds of fusion clearer.


  > the technical objectives were not stated clearly enough
  > to help the reader assess the proposed contribution.
The last paragraph of the introduction was rewritten to separate the technical
objectives from the contributions and the solutions on how to achieve the objectives.


  > the evaluation lacked a clear assessment of the main features
  > of the system, in particular the integration of MER in the visualization,
  > and that the benefits of this system in the clinical setting were not
  > well documented.
We went back to an expert with this comment and received a reply that we included in the
text (Section 3).


  > Specifically:
  > 1. clarify the technical objectives 
  > 2. explain more fully the relationship between the objectives and the
  > contributions.
The last chapter of the introduction as well as the conclusions were rewritten to clarify
the technical objectives

  > 3. provide a clear assessment of the main features of your system
  > 4. clarify the benefits of this system in the clinical setting. 
Changed various places in the text to clarify the features and objectives. Furthermore,
we received a statement from an expert:
Multimodal image fusion and image guided surgerys are well established tools in the field
of neurosurgery. In contrast to classical image fusion the depicted system provides
additional functional MER information within a common framework of advanced 3D imaging
technology. This new setup allows the surgeon for a rapid assessment and control of the
target area. Up to now the different tools for aiding surgery are realized within separated
units like MER toolbox, trajectory planning system and x-ray control system. Every system
needs complex user interaction with a different user interface and provides information to
the surgeon in a specific way. Due to limited capacity of the staff the user interaction as
to be performed serially, which prolongs the exhaustive testing procedure for the patient.
The new system integrates all of the desired technical information within one single user
interface and provides a single advanced view containing all information for the surgeon.
Thus, orientation of trajectories in respect to the target area and additional functional
MER data become visible for the surgeon at the same time. This reduces mental workload of
the surgeon and helps speeding up MER guided DBS surgery at a very high confidence level of
target control.  


  > Potentially, the target closeup visualization, which includes the
  > "fusing of multimodal uncertainty regions" from the paper title, could be
  > the most important contribution. Unfortunately, Fig.6 seems rather
  > confusing to me, and the text in Sec.3.4.1 does not make it easy to
  > understand how this visualization would contribute to a more accurate
  > localization in practice. In the evaluation sheet, either the
  > neurosurgeons were not asked about this central part of the system, or
  > the authors decided not to report this question and its answers.
The caption of Figure 6 was rewritten and the Section 3.4.1 improved to hopefully remove
the confusion.


  > The neurosurgeons were asked to compare the system to their "old
  > system", but it does not become clear to the reader what the features of
  > that "old system" are.
<<Include screenshot of old system?>>


  > The user interface seems rather complex - several parameters are left
  > for "manual adjustment" by the user, and it is unclear if the surgery
  > team will have the time for that during the intervention.
Some of the not necessary parameters (Section 3.2.1) were removed.
  
  
  > The authors state that the system should "reduce the cognitive load"
  > of the surgeon, but the specific benefits expected from the system are
  > not described in large enough detail. Is the system expected to make the
  > intervention faster (despite the described complexity in using it)?
  > Should it lead to higher success rates (if so, are there clinical studies
  > that indicate how many such interventions fail any why)?
Please see the statement in the question above. Parts of this was included in the text
in various places.


  > A more common visualization term for the "beads" would by "glyphs".
'Beads' are characterized as 'glyphs' in the text now


  > The paper presents a system that contains many interesting tools to
  > display data during surgery. The main problem I see with this paper is
  > that, being a systems description, it does not provide enough content
  > about the usability of various parts of the system. The descriptions of
  > the individual parts seem sound, even though the authors do not provide a
  > lot of detail and, therefore, limited technical novelty is contained in
  > the paper.


  > One major drawback of the paper, which influenced my decision is the
  > fact, that the quality of the interventions is not measured. Neither in
  > the testing phase at the end of the paper, nor evaluated in the technical
  > description. This is especially due to the fact that a high accuracy is
  > claimed to be mandatory (approx. 1mm), where most measurements provided
  > during the surgery typically do not provide this accuracy in the
  > measurement.
The future work section was extended to make it clearer that we plan to perform
exactly these measurements as a second step.


  > Even thought the title talks about uncertain regions, I think this fact
  > is underrepresented in the system. It is mentioned that the segmentation
  > is "uncertain" as the brain shifted, but the brain is captured several
  > times during the surgery using CT to recalibrate all devices.
Brain shift is only one of the reasons for the uncertainty of the electrode's position. A
sentence and a reference about predicting the brain shift was added to the section. It is
true that the skull is x-ray scanned repeatedly during the operation, but this cannot be
used to measure the uncertainty of the segmentation, as the target region is completely
invisible on this modality. It is solely used to reconstruct the electrode's position as
these are x-ray opaque.


  > Section 3.2.1: "As MRI has a low signal-to-noise ratio, gradient-based
  > shading is not viable when visualizing the brain.": In my experience,
  > especially T1 images have a reasonable SNR and can be used easily for
  > volume representations, especially because in most cases, iso surfaces
  > can be computed and have shown to be stable enough.
The sentence was rewritten and a new reference has been added. It was made clearer that
gradient shading of course works on T1 weighted images, but that we found Depth Darkening
to provide a superior depth perception.


  > "We present the access path to the surgeon by removing the structures
  > around the trajectory"
  > I am not sure whether removing the structure around the access path is
  > provides enough guidance. As far as I know, the access path is usually
  > identified using the local structures, which would have been removed in
  > this case. Please clarify.
Text was added to that section to make the idea of the access path clearer. The access
path is mainly carved out to provide room for the glyphs being added along the trajectory
as well as, on a minor note, for accessing the canal walls.


  > 1. I would like to see more discussions on fused visualization. In my
  > view, only Figure 7 strictly quality as fused uncertainty visualization,
  > while Figure 5 seems to focus on MER only (though the word fusing is
  > used). Figure 6 seems to be a fused visualization, but I am not sure
  > where is uncertainty.
A better distinction between qualitative and quantitative fusion was drawn in the caption
as well as in the text. The caption of Figure 5 saw the word 'fusing' replaced by
'combining' to increase readability.


  > 2. Although the title has a phrase "Fusing Multimodal Uncertainty
  > Regions", the paper seems unsure about what exactly it tries to do. Is it
  > about fusing different modalities as in Figure 6 (through I am not sure
  > if all mentioned modalities are there)? Is it about the fusion of
  > different uncertainty values (as in Figure 7). Is it about fusing
  > different aspects of MER data as in Figure 5.
The last paragraph of the introduction was rewritten to make the two disting fusing
techniques, i.e., fusion between structural and functional modalities and fusion of 
uncertainty values, easier to distinguish.


  > 3. It is also not clear if the authors try to claim novelty from a
  > perspective of an application system or a set of apparently uncoordinated
  > views or visual designs in the paper. In fact, the first part of the
  > video shows a reasonable coordinated set of 4 views. Why not add such an
  > image (or even better screenshot) into the paper? 
Screenshots of the system's various phases were added to the paper to make the focus on
an application system more prominent.


  > It is an exciting application. The video is reasonably good. I would like
  > the paper to take us through different stages in the surgical planning to
  > show us how different views are used, and ideally through the same
  > system. Are the two parts of video from the same system?
A workflow figure was added to provide a better overview of the different stages as well
as screenshots for the each of the phases. The video was created using a single system,
but was recorded in two different instances. Furthermore, the individual canvasses were
separated in the last part of the movie to be able to orient them differently.
